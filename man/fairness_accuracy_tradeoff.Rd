% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/visualize.R
\name{fairness_accuracy_tradeoff}
\alias{fairness_accuracy_tradeoff}
\title{Fairness Accuracy Tradeoff Visualization}
\usage{
fairness_accuracy_tradeoff(object, ...)
}
\arguments{
\item{object}{(\link{PredictionClassif})\cr (\link{BenchmarkResult})\cr (\link{ResampleResult})\cr
The binary class prediction object that will be evaluated. Only one data task is allowed for BenchmarkResult or ResampleResult
\itemize{
\item If provided a (\link{PredictionClassif}). Then only one point will indicate the accuracy and fairness metrics for the current predictions.
\item If provided a (\link{ResampleResult}). Then the plot will compare the accuracy and fairness metrics for the same model, but different resampling iterations.
\item If provided a (\link{BenchmarkResult}). Then the plot will compare the accuracy and fairness metrics for all models and all resampling iterations.
}}

\item{...}{Arguments to be passed to methods. Such as:
\itemize{
\item \code{fairness_measure} (\link{Measure})\cr
The fairness measures that will evaluated on object, could be single measure (\code{msr}) or list of measures (\code{msrs}), check \link[mlr3:Measure]{mlr3::Measure}. Default measure set to be \code{msr("fairness.fpr")}
\item \code{accuracy_measure} (\link{Measure})\cr
The accuracy measure that will evaluated on object, could be single measure \link{msr} or measures \link{msrs}. Default measure set to be \code{\link[mlr3:MeasureClassif]{msr("classif.acc")}}
\item \code{task} (\link{TaskClassif})\cr
The data task that contains the protected column, only required when the class of object is (\link{PredictionClassif})
}}
}
\description{
These functions specialize in comparing the Fairness and Accuracy between learners through visualizations.
From the visualization, users could see the tradeoff between fairness metrics and accuracy.
Those insights could help the users to choose the optimum model from their model sets.
And the fairness consistency of the learners by visualizing the tradeoff for different resampling iterations.
It could take multiple types of inputs, like (\link{PredictionClassif}), (\link{BenchmarkResult}) and (\link{ResampleResult}).
}
\examples{
library(mlr3fairness)
library(mlr3learners)
library(mlr3)
library(ggplot2)
library(data.table)

# Setup the Fairness Measures and tasks
task = tsk("adult_train")
learner = lrn("classif.ranger", predict_type = "prob")
learner$train(task)
predictions = learner$predict(task)
design = benchmark_grid(
  tasks = tsk("adult_train"),
  learners = lrns(c("classif.ranger", "classif.rpart"),
                 predict_type = "prob", predict_sets = c("train", "test")),
  resamplings = rsmps("cv", folds = 3)
)

bmr = benchmark(design)
fairness_measure = msr("fairness.tpr")
fairness_measures = msrs(c("fairness.tpr", "fairness.fnr"))

fairness_accuracy_tradeoff(predictions, fairness_measure, task)
fairness_accuracy_tradeoff(bmr, fairness_measure)
}
