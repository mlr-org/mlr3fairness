@Manual{R,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2021},
  url = {http://www.R-project.org/},
}

@Article{mlr3,
    title = {{mlr3}: A modern object-oriented machine learning framework in {R}},
    author = {Michel Lang and Martin Binder and Jakob Richter and Patrick Schratz and Florian Pfisterer and Stefan Coors and Quay Au and Giuseppe Casalicchio
    and Lars Kotthoff and Bernd Bischl},
    journal = {Journal of Open Source Software},
    year = {2019},
    month = {dec},
    doi = {10.21105/joss.01903}
}

@Article{mlr3pipelines,
    title = {{mlr3pipelines - Flexible Machine Learning Pipelines in R}},
    author = {Martin Binder and Florian Pfisterer and Michel Lang and Lennart Schneider and Lars Kotthoff and Bernd Bischl},
    journal = {Journal of Machine Learning Research},
    year = {2021},
    volume = {22},
    number = {184},
    pages = {1-7},
    url = {https://jmlr.org/papers/v22/21-0281.html},
}

@Article{mlr3proba,
    title = {{mlr3proba: An R Package for Machine Learning in Survival Analysis}},
    author = {Raphael Sonabend and Franz J Király and Andreas Bender and Bernd Bischl and Michel Lang},
    journal = {Bioinformatics},
    month = {02},
    year = {2021},
    doi = {10.1093/bioinformatics/btab039},
}

@article{Vanschoren2014,
  doi = {10.1145/2641190.2641198},
  year = {2014},
  month = jun,
  publisher = {Association for Computing Machinery ({ACM})},
  volume = {15},
  number = {2},
  pages = {49--60},
  author = {Joaquin Vanschoren and Jan N. van Rijn and Bernd Bischl and Luis Torgo},
  title = {{OpenML}},
  journal = {{ACM} {SIGKDD} Explorations Newsletter}
}

@article{galindo2000credit,
  title={Credit risk assessment using statistical and machine learning: basic methodology and risk modeling applications},
  author={Galindo, Jorge and Tamayo, Pablo},
  journal={Computational Economics},
  volume={15},
  number={1},
  pages={107--143},
  year={2000},
  publisher={Springer}
}

@Manual{caret,
title = {caret: Classification and Regression Training},
author = {Max Kuhn},
year = {2021},
note = {R package version 6.0-88},
url = {https://CRAN.R-project.org/package=caret},
}

@Manual{superlearner,
title = {SuperLearner: Super Learner Prediction},
author = {Eric Polley and Erin LeDell and Chris Kennedy and Mark {van der Laan}},
year = {2021},
note = {R package version 2.0-28},
url = {https://CRAN.R-project.org/package=SuperLearner},
}

@Manual{tidymodels,
title = {Tidymodels: a collection of packages for modeling and machine learning using tidyverse principles.},
author = {Max Kuhn and Hadley Wickham},
url = {https://www.tidymodels.org},
year = {2020},
}

@article{mcboost,
  author = {Pfisterer, Florian and Kern, Christoph and Dandl, Susanne and Sun, Matthew and
  Kim, Michael P. and Bischl, Bernd},
  title = {mcboost: Multi-Calibration Boosting for {R}},
  journal = {Journal of Open Source Software},
  doi = {10.21105/joss.03453},
  url = {https://github.com/mlr-org/mcboost},
  year = {2021},
  publisher = {The Open Journal},
  volume = {6},
  number = {64},
  pages = {3453}
}

  # Multi-Calibration
  @inproceedings{hebert-johnson2018,
    title = {Multicalibration: Calibration for the ({C}omputationally-Identifiable) Masses},
    author = {Hebert-Johnson, Ursula and Kim, Michael P. and Reingold, Omer and Rothblum, Guy},
    booktitle = {Proceedings of the 35th International Conference on Machine Learning},
    pages = {1939--1948},
    year = {2018},
    editor = {Jennifer Dy and Andreas Krause},
    volume = {80},
    series = {Proceedings of Machine Learning Research},
    address = {Stockholmsmässan, Stockholm Sweden},
    publisher = {PMLR}
  }
  # Multi-Accuracy
  @inproceedings{kim2019,
    author = {Kim, Michael P. and Ghorbani, Amirata and Zou, James},
    title = {Multiaccuracy: Black-Box Post-Processing for Fairness in Classification},
    year = {2019},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    doi = {10.1145/3306618.3314287},
    booktitle = {Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
    pages = {247--254},
    location = {Honolulu, HI, USA},
    series = {AIES '19}
  }

@misc{uci ,
    author = "Dua, Dheeru and Graff, Casey",
    year = "2017",
    title = "{UCI} Machine Learning Repository",
    url = "http://archive.ics.uci.edu/ml",
    institution = "University of California, Irvine, School of Information and Computer Sciences"
}


# Fairness
@book{fairmlbook,
  title = {Fairness and Machine Learning},
  author = {Solon Barocas and Moritz Hardt and Arvind Narayanan},
  publisher = {fairmlbook.org},
  note = {\url{http://www.fairmlbook.org}},
  year = {2019}
}

@article{dawes1989clinical,
  title={Clinical versus actuarial judgment},
  author={Dawes, Robyn M and Faust, David and Meehl, Paul E},
  journal={Science},
  volume={243},
  number={4899},
  pages={1668--1674},
  year={1989},
  publisher={American Association for the Advancement of Science}
}

@article{barocas2016big,
  title={Big data's disparate impact},
  author={Barocas, Solon and Selbst, Andrew D},
  journal={Calif. L. Rev.},
  volume={104},
  pages={671},
  year={2016},
  publisher={HeinOnline}
}


@article{rodolfa2020machine,
  title={Machine learning for public policy: Do we need to sacrifice accuracy to make models fair?},
  author={Rodolfa, Kit T and Lamba, Hemank and Ghani, Rayid},
  journal={arXiv preprint arXiv:2012.02972},
  year={2020}
}

@misc{compas,
author = {Julia Angwin and Jeff Larson and Surya Mattu and Lauren Kichner},
publisher = {ProPublica},
url = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
year = 2016,
month = may,
day = 23,
title = {Machine Bias},
}

@inproceedings{corbettcompas,
author = {Corbett-Davies, Sam and Pierson, Emma and Feller, Avi and Goel, Sharad and Huq, Aziz},
title = {Algorithmic Decision Making and the Cost of Fairness},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098095},
doi = {10.1145/3097983.3098095},
abstract = {Algorithms are now regularly used to decide whether defendants awaiting trial are too dangerous to be released back into the community. In some cases, black defendants are substantially more likely than white defendants to be incorrectly classified as high risk. To mitigate such disparities, several techniques have recently been proposed to achieve algorithmic fairness. Here we reformulate algorithmic fairness as constrained optimization: the objective is to maximize public safety while satisfying formal fairness constraints designed to reduce racial disparities. We show that for several past definitions of fairness, the optimal algorithms that result require detaining defendants above race-specific risk thresholds. We further show that the optimal unconstrained algorithm requires applying a single, uniform threshold to all defendants. The unconstrained algorithm thus maximizes public safety while also satisfying one important understanding of equality: that all individuals are held to the same standard, irrespective of race. Because the optimal constrained and unconstrained algorithms generally differ, there is tension between improving public safety and satisfying prevailing notions of algorithmic fairness. By examining data from Broward County, Florida, we show that this trade-off can be large in practice. We focus on algorithms for pretrial release decisions, but the principles we discuss apply to other domains, and also to human decision makers carrying out structured decision rules.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {797–806},
numpages = {10},
keywords = {discrimination, pretrial detention, algorithmic fairness, risk assessment, disparate impact},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@article{corbett2018measure,
  title={The measure and mismeasure of fairness: A critical review of fair machine learning},
  author={Corbett-Davies, Sam and Goel, Sharad},
  journal={arXiv preprint arXiv:1808.00023},
  year={2018}
}

@article{richardcompas,
author = {Richard Berk and Hoda Heidari and Shahin Jabbari and Michael Kearns and Aaron Roth},
title ={{Fairness in Criminal Justice Risk Assessments: The State of the Art}},
journal = {Sociological Methods \& Research},
numpages = {42},
year = {2018},
month = aug,
eprint = {1703.09207},
archiveprefix = {arXiv},
doi = {10.1177/0049124118782533}
}

@article{Topol2019,
abstract = {The use of artificial intelligence, and the deep-learning subtype in particular, has been enabled by the use of labeled big data, along with markedly enhanced computing power and cloud storage, across all sectors. In medicine, this is beginning to have an impact at three levels: for clinicians, predominantly via rapid, accurate image interpretation; for health systems, by improving workflow and the potential for reducing medical errors; and for patients, by enabling them to process their own data to promote health. The current limitations, including bias, privacy and security, and lack of transparency, along with the future directions of these applications will be discussed in this article. Over time, marked improvements in accuracy, productivity, and workflow will likely be actualized, but whether that will be used to improve the patient–doctor relationship or facilitate its erosion remains to be seen.},
author = {Topol, Eric J.},
doi = {10.1038/s41591-018-0300-7},
journal = {Nature Medicine},
number = {1},
pages = {44--56},
title = {High-performance medicine: the convergence of human and artificial intelligence},
volume = {25},
year = {2019}
}


@book{eubanks2018automating,
  title={Automating inequality: How high-tech tools profile, police, and punish the poor},
  author={Eubanks, Virginia},
  year={2018},
  publisher={St. Martin's Press}
}

@book{o2016weapons,
  title={Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy},
  author={O'neil, Cathy},
  year={2016},
  publisher={Crown}
}

@book{noble2018algorithms,
  title={Algorithms of Oppression},
  author={Noble, Safiya Umoja},
  year={2018},
  publisher={New York University Press}
}

@inproceedings{Chen2019,
archivePrefix = {arXiv},
author = {Chen, Jiahao and Kallus, Nathan and Mao, Xiaojie and Svacha, Geofry and Udell, Madeleine},
booktitle = {FAT* 2019 - Proceedings of the 2019 Conference on Fairness, Accountability, and Transparency},
doi = {10.1145/3287560.3287594},
eprint = {1811.11154},
pages = {339--348},
title = {Fairness under unawareness: Assessing disparity when protected class is unobserved},
year = {2019}
}

@inproceedings{Turner2019,
author = {Turner, Matthew and McBurnett, Michael},
booktitle = {Proceedings of the 15th Credit Scoring and Credit Control Conference},
title = {Predictive models with explanatory concepts: a general framework for explaining machine learning credit risk models that simultaneously increases predictive power},
url = {https://crc.business-school.ed.ac.uk/wp-content/uploads/sites/55/2019/07/C12-Predictive-Models-with-Explanatory-Concepts-McBurnett.pdf},
year = {2019},
numpages = 11
}

@inproceedings{schumann,
author = {Schumann, Candice and Foster, Jeffrey S. and Mattei, Nicholas and Dickerson, John P.},
title = {We Need Fairness and Explainability in Algorithmic Hiring},
year = {2020},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Algorithms and machine learning models, including the decisions made by these models,
are becoming ubiquitous in our daily life, including hiring. We make no value judgment
regarding this development; rather, we simply acknowledge that it is quickly becoming
reality that automation plays a role in hiring. Increasingly, these technologies are
used in all of the small decisions that make up the modern hiring pipeline: from which
resumes get selected for a first screen to who gets an on site interview. Thus, these
algorithms and models may potentially amplify bias and (un)fairness issues for many
historically marginalized groups. While there is a rapidly expanding literature on
algorithmic decision making and fairness, there has been limited work on fairness
specifically for online, multi-stakeholder decision making processes such as those
found in hiring. We outline broad challenges including formulating definitions for
fair treatment and fair outcomes in hiring, and incorporating these definitions into
the algorithms and processes that constitute the modern hiring pipeline. We see the
AAMAS community as uniquely positioned to address these challenges.},
booktitle = {Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1716–1720},
numpages = {5},
keywords = {blue sky, bandits, algorithmic fairness},
location = {Auckland, New Zealand},
series = {AAMAS '20}
}

@article{khandani2010,
  title={Consumer credit-risk models via machine-learning algorithms},
  author={Khandani, Amir E and Kim, Adlar J and Lo, Andrew W},
  journal={Journal of Banking \& Finance},
  volume={34},
  number={11},
  pages={2767--2787},
  year={2010},
  publisher={Elsevier}
}

@article{mehrabi,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{hardt2016equality,
  title={Equality of opportunity in supervised learning},
  author={Hardt, Moritz and Price, Eric and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={29},
  pages={3315--3323},
  year={2016}
}

@article{saleiro2018aequitas,
  title={Aequitas: A bias and fairness audit toolkit},
  author={Saleiro, Pedro and Kuester, Benedict and Hinkson, Loren and London, Jesse and Stevens, Abby and Anisfeld, Ari and Rodolfa, Kit T and Ghani, Rayid},
  journal={arXiv preprint arXiv:1811.05577},
  year={2018}
}

@inproceedings{kim2020fact,
  title={Fact: A diagnostic for group fairness trade-offs},
  author={Kim, Joon Sik and Chen, Jiahao and Talwalkar, Ameet},
  booktitle={International Conference on Machine Learning},
  pages={5264--5274},
  year={2020},
  organization={PMLR}
}

@article{kamiran2012data,
  title={Data preprocessing techniques for classification without discrimination},
  author={Kamiran, Faisal and Calders, Toon},
  journal={Knowledge and Information Systems},
  volume={33},
  number={1},
  pages={1--33},
  year={2012},
  publisher={Springer}
}



## Software


 @Manual{fairness,
    title = {fairness: Algorithmic Fairness Metrics},
    author = {Nikita Kozodoi and Tibor {V. Varga}},
    year = {2021},
    note = {R package version 1.2.1},
    url = {https://CRAN.R-project.org/package=fairness},
  }

@article{aif360,
  title={{AI Fairness 360}: An extensible toolkit for detecting and mitigating algorithmic bias},
  author={Bellamy, Rachel KE and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovi{\'c}, Aleksandra and others},
  journal={IBM Journal of Research and Development},
  volume={63},
  number={4/5},
  pages={4--1},
  year={2019},
  publisher={IBM}
}

@Article{DALEX,
  title = {{DALEX}: {Explainers for Complex Predictive Models} in {R}},
  author = {Przemyslaw Biecek},
  journal = {Journal of Machine Learning Research},
  year = {2018},
  volume = {19},
  pages = {1-5},
  number = {84},
  url = {https://jmlr.org/papers/v19/18-416.html},
}

@book{molnar2019, title = {Interpretable Machine Learning},
author = {Christoph Molnar},
year = {2019},
subtitle = {A Guide for Making Black Box Models Explainable} }

@techreport{fairlearn,
    author = {Bird, Sarah and Dud{\'i}k, Miro and Edgar, Richard and Horn, Brandon and Lutz, Roman and Milan, Vanessa and Sameki, Mehrnoosh and Wallach, Hanna and Walker, Kathleen},
    title = {Fairlearn: A toolkit for assessing and improving fairness in {AI}},
    institution = {Microsoft},
    year = {2020},
    month = {May},
    url = "https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/",
    number = {MSR-TR-2020-32},
}

@article{sklearn,
  title={Scikit-learn: Machine learning in Python},
  author={Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011},
  publisher={JMLR. org}
}

@misc{fairnessjl,
  author       = {Ashrya Agrawal and Jiahao Chen and Sebastian Vollmer and Anthony Blaom},
  title        = {Fairness.jl},
  year         = {2020},
  publisher    = {Zenodo},
  version      = {v0.1.2},
  doi          = {10.5281/zenodo.3977197},
  url          = {https://github.com/ashryaagr/Fairness.jl}
}

@article{pfisterer2019multiobjective,
  title={Multi-Objective Automatic Machine Learning with AutoxgboostMC},
  author={Florian Pfisterer and Stefan Coors and Janek Thomas and Bernd Bischl},
  year={2019},
  journal={arXiv preprint arXiv:1908.10796},
}

@inproceedings{feldman2015certifying,
  title={Certifying and removing disparate impact},
  author={Feldman, Michael and Friedler, Sorelle A and Moeller, John and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  booktitle={Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={259--268},
  year={2015}
}

@article{chouldechova2017fair,
  archivePrefix = {arXiv},
  author = {Chouldechova, Alexandra},
  doi = {10.1089/big.2016.0047},
  eprint = {1703.00056},
  journal = {Big Data},
  month = jun,
  number = {2},
  pages = {153--163},
  title = {Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments},
  volume = {5},
  year = {2017}
}

@article{mlr,
    title = {mlr: Machine Learning in {R}},
    author = {Bernd Bischl and Michel Lang and Lars Kotthoff and Julia Schiffner and Jakob Richter and Erich Studerus
      and Giuseppe Casalicchio and Zachary M. Jones},
    journal = {Journal of Machine Learning Research},
    year = {2016},
    volume = {17},
    number = {170},
    pages = {1-5},
    url = {https://jmlr.org/papers/v17/15-066.html}
}

@inproceedings{Chen2018,
  archivePrefix = {arXiv},
  author = {Chen, Jiahao},
  eprint = {1809.04684},
  booktitle = {Proceedings of the 2nd FATREC Workshop on Responsible Recommendation},
  month = sep,
  numpages = {4},
  title = {Fair lending needs explainable models for responsible recommendation},
  year = {2018}
}

 @Book{rmarkdown,
    title = {R Markdown Cookbook},
    author = {Yihui Xie and Christophe Dervieux and Emily Riederer},
    publisher = {Chapman and Hall/CRC},
    address = {Boca Raton, Florida},
    year = {2020},
    url = {https://bookdown.org/yihui/rmarkdown-cookbook},
  }



@inproceedings{modelcards,
author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
title = {Model Cards for Model Reporting},
year = {2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3287560.3287596},
booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
pages = {220–229},
location = {Atlanta, GA, USA},
series = {FAT* '19}
}

@article{datasheets,
  title={Datasheets for datasets},
  author={Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Iii, Hal Daum{\'e} and Crawford, Kate},
  journal={Communications of the ACM},
  volume={64},
  number={12},
  pages={86--92},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{gendershades,
  title={{Gender shades: Intersectional accuracy disparities in commercial gender classification}},
  author={Buolamwini, Joy and Gebru, Timnit},
  booktitle={Conference on Fairness, Accountability, and Transparency},
  pages={77--91},
  year={2018},
  organization={PMLR}
}

@article{Calders2010,
author = {Calders, Toon and Verwer, Sicco},
doi = {10.1007/s10618-010-0190-x},
journal = {Data Mining and Knowledge Discovery},
number = {2},
pages = {277--292},
title = {{Three naive Bayes approaches for discrimination-free classification}},
volume = {21},
year = {2010}
}

@inproceedings{perrone2021fair,
  title={{Fair Bayesian Optimization}},
  author={Perrone, Valerio and Donini, Michele and Zafar, Muhammad Bilal and Schmucker, Robin and Kenthapadi, Krishnaram and Archambeau, C{\'e}dric},
  booktitle={Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={854--863},
  year={2021}
}


@inproceedings{Zafar2017,
address = {Geneva, Switzerland},
author = {Zafar, Muhammad Bilal and Valera, Isabel and {Gomez Rodriguez}, Manuel and Gummadi, Krishna P.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
doi = {10.1145/3038912.3052660},
month = apr,
pages = {1171--1180},
publisher = {International World Wide Web Conferences Steering Committee},
title = {{Fairness beyond Disparate treatment {\&} Disparate Impact}},
year = {2017}
}

@article{mitchell2021algorithmic,
  title={{Algorithmic fairness: Choices, assumptions, and definitions}},
  author={Mitchell, Shira and Potash, Eric and Barocas, Solon and D'Amour, Alexander and Lum, Kristian},
  journal={Annual Review of Statistics and Its Application},
  volume={8},
  pages={141--163},
  year={2021},
  publisher={Annual Reviews}
}

@article{scutari,
  title={Achieving Fairness with a Simple Ridge Penalty},
  author={Scutari, Marco and Panero, Francesca and Proissl, Manuel},
  journal={arXiv preprint arXiv:2105.13817},
  year={2021}
}

@inproceedings{komiyama,
  title={Nonconvex optimization for regression with fairness constraints},
  author={Komiyama, Junpei and Takeda, Akiko and Honda, Junya and Shimao, Hajime},
  booktitle={International Conference on Machine Learning},
  pages={2737--2746},
  year={2018},
  organization={PMLR}
}

@misc{chen22,
  doi = {10.48550/ARXIV.2202.09519},
  url = {https://arxiv.org/abs/2202.09519},
  author = {Watkins, Elizabeth Anne and McKenna, Michael and Chen, Jiahao},
   title = {The four-fifths rule is not disparate impact: a woeful tale of epistemic trespassing in algorithmic fairness},
  publisher = {arXiv},
  year = {2022}
}

@article{fairmodels,
  title = {fairmodels: a Flexible Tool for Bias Detection, Visualization, and Mitigation in Binary Classification Models},
  author = {Jakub Wiśniewski and Przemysław Biecek},
  year = {2022},
  journal = {The R Journal},
  volume = {14},
  issue = {1},
  pages = {227-243},
  url = {https://rj.urbanek.nz/articles/RJ-2022-019/},
}

@misc{mlr3book,
  title = {mlr3book},
  author = {Marc Becker and Martin Binder and Natalie Foss and Lars Kotthoff and Michel Lang and Florian Pfisterer and Nicholas G. Reich and Jakob Richter and Patrick Schratz and Raphael Sonabend and Damir Pulatov and Bernd Bischl},
  url = {https://mlr3book.mlr-org.com},
  year = {2022},
  month = {09},
  day = {25},
}

@article{wachter-vlr2020,
  title={Bias preservation in machine learning: the legality of fairness metrics under {EU} non-discrimination law},
  author={Wachter, S. and Mittelstadt, B. and Russell, C.},
  journal={West Virginia Law Review},
  volume={123},
  year={2020},
  publisher={West Virginia University College of Law}
}

@inproceedings{bao2021s,
  title={It's COMPASlicated: The Messy Relationship between RAI Datasets and Algorithmic Fairness Benchmarks},
  author={Bao, Michelle and Zhou, Angela and Zottola, Samantha A and Brubach, Brian and Desmarais, Sarah and Horowitz, Aaron Seth and Lum, Kristian and Venkatasubramanian, Suresh},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},
  year={2021}
}

@inproceedings{schwobel-facct22a,
  title={The Long Arc of Fairness: Formalisations and Ethical Discourse},
  author={P. Schwöbel and P. Remmers},
  booktitle={Proceedings of the Conference on Fairness, Accountability, and Transparency (FAccT’22)},
  year = {2022}
}

@misc{friedler16,
  url = {https://arxiv.org/abs/1609.07236},
  author = {Friedler, Sorelle A. and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  keywords = {Computers and Society (cs.CY), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {On the (im)possibility of fairness},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{bischl2012resampling,
  title={Resampling methods for meta-model validation with recommendations for evolutionary computation},
  author={Bischl, Bernd and Mersmann, Olaf and Trautmann, Heike and Weihs, Claus},
  journal={Evolutionary Computation},
  volume={20},
  number={2},
  pages={249--275},
  year={2012},
  publisher={MIT Press}
}

@inproceedings{dwork2012,
  title={Fairness through awareness},
  author={Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
  booktitle={Proceedings of the 3rd Innovations in Theoretical Computer Science Conference},
  pages={214--226},
  year={2012}
}

@inproceedings{binns2020apparent,
  title={On the apparent conflict between individual and group fairness},
  author={Binns, Reuben},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={514--524},
  year={2020},
  series = {FAT* '20}
}

@inproceedings{heidari2019,
author = {Heidari, Hoda and Loi, Michele and Gummadi, Krishna P. and Krause, Andreas},
title = {A Moral Framework for Understanding Fair ML through Economic Models of Equality of Opportunity},
year = {2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3287560.3287584},
abstract = {We map the recently proposed notions of algorithmic fairness to economic models of Equality of opportunity (EOP)---an extensively studied ideal of fairness in political philosophy. We formally show that through our conceptual mapping, many existing definition of algorithmic fairness, such as predictive value parity and equality of odds, can be interpreted as special cases of EOP. In this respect, our work serves as a unifying moral framework for understanding existing notions of algorithmic fairness. Most importantly, this framework allows us to explicitly spell out the moral assumptions underlying each notion of fairness, and interpret recent fairness impossibility results in a new light. Last but not least and inspired by luck egalitarian models of EOP, we propose a new family of measures for algorithmic fairness. We illustrate our proposal empirically and show that employing a measure of algorithmic (un)fairness when its underlying moral assumptions are not satisfied, can have devastating consequences for the disadvantaged group's welfare.},
booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
pages = {181–190},
numpages = {10},
keywords = {Equality of Odds, Statistical Parity, Rawlsian and Luck Egalitarian EOP, Fairness for Machine Learning, Predictive Value Parity, Equality of Opportunity (EOP)},
location = {Atlanta, GA, USA},
series = {FAT* '19}
}

@article{kilbertus2017avoiding,
  title={Avoiding discrimination through causal reasoning},
  author={Kilbertus, Niki and Rojas Carulla, Mateo and Parascandolo, Giambattista and Hardt, Moritz and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@InProceedings{fairwashing,
  title = 	 {Fairwashing: the risk of rationalization},
  author =       {Aivodji, Ulrich and Arai, Hiromi and Fortineau, Olivier and Gambs, S{\'e}bastien and Hara, Satoshi and Tapp, Alain},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {161--170},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/aivodji19a/aivodji19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/aivodji19a.html},
  abstract = 	 {Black-box explanation is the problem of explaining how a machine learning model – whose internal logic is hidden to the auditor and generally complex – produces its outcomes. Current approaches for solving this problem include model explanation, outcome explanation as well as model inspection. While these techniques can be beneficial by providing interpretability, they can be used in a negative manner to perform fairwashing, which we define as promoting the false perception that a machine learning model respects some ethical values. In particular, we demonstrate that it is possible to systematically rationalize decisions taken by an unfair black-box model using the model explanation as well as the outcome explanation approaches with a given fairness metric. Our solution, LaundryML, is based on a regularized rule list enumeration algorithm whose objective is to search for fair rule lists approximating an unfair black-box model. We empirically evaluate our rationalization technique on black-box models trained on real-world datasets and show that one can obtain rule lists with high fidelity to the black-box model while being considerably less unfair at the same time.}
}

@misc{agrawal2020debiasing,
      title={Debiasing classifiers: is reality at variance with expectation?},
      author={Ashrya Agrawal and Florian Pfisterer and Bernd Bischl and Jiahao Chen and Srijan Sood and Sameena Shah and Francois Buet-Golfouse and Bilal A Mateen and Sebastian Vollmer},
      year={2020},
      eprint={arXiv:2011.02407},
      note={arXiv:2011.02407},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{cirillo2020sex,
  title={Sex and gender differences and biases in artificial intelligence for biomedicine and healthcare},
  author={Cirillo, Davide and Catuara-Solarz, Silvina and Morey, Czuee and Guney, Emre and Subirats, Laia and Mellino, Simona and Gigante, Annalisa and Valencia, Alfonso and Rementeria, Mar{\'\i}a Jos{\'e} and Chadha, Antonella Santuccione and others},
  journal={NPJ digital medicine},
  volume={3},
  number={1},
  pages={1--11},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{kozodoi2022fairness,
  title={Fairness in credit scoring: Assessment, implementation and profit implications},
  author={Kozodoi, Nikita and Jacob, Johannes and Lessmann, Stefan},
  journal={European Journal of Operational Research},
  volume={297},
  number={3},
  pages={1083--1094},
  year={2022},
  publisher={Elsevier}
}