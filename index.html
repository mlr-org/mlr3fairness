<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content='
    Integrates fairness auditing and bias mitigation methods for the mlr3 ecosystem.
    This includes fairness metrics, reporting tools, visualizations and bias mitigation techniques such as
    "Reweighing" described in Kamiran, Calders (2012) &lt;doi:10.1007/s10115-011-0463-8&gt;  and
    "Equalized Odds" described in Hardt et al. (2016) &lt;https://papers.nips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf&gt;.
    Integration with mlr3 allows for auditing of ML models as well as convenient joint tuning of
    machine learning algorithms and debiasing methods.'>
<title>Fairness Auditing and Debiasing for mlr3 • mlr3fairness</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="apple-touch-icon-60x60.png">
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><link href="deps/Roboto-0.4.5/font.css" rel="stylesheet">
<link href="deps/JetBrains_Mono-0.4.5/font.css" rel="stylesheet">
<link href="deps/Roboto_Slab-0.4.5/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Fairness Auditing and Debiasing for mlr3">
<meta property="og:description" content='
    Integrates fairness auditing and bias mitigation methods for the mlr3 ecosystem.
    This includes fairness metrics, reporting tools, visualizations and bias mitigation techniques such as
    "Reweighing" described in Kamiran, Calders (2012) &lt;doi:10.1007/s10115-011-0463-8&gt;  and
    "Equalized Odds" described in Hardt et al. (2016) &lt;https://papers.nips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf&gt;.
    Integration with mlr3 allows for auditing of ML models as well as convenient joint tuning of
    machine learning algorithms and debiasing methods.'>
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="index.html">mlr3fairness</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.3.2</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="reference/index.html">
    <span class="fa fa fa fa-file-alt"></span>
     
    Reference
  </a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="articles/debiasing-vignette.html">Debiasing Methods</a>
    <a class="dropdown-item" href="articles/measures-vignette.html">Fairness Metrics</a>
    <a class="dropdown-item" href="articles/reports-vignette.html">Reports</a>
    <a class="dropdown-item" href="articles/visualization-vignette.html">Fairness Visualizations</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="news/index.html">Changelog</a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://mlr3book.mlr-org.com">
    <span class="fa fa fa fa-link"></span>
     
    mlr3book
  </a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/mlr-org/mlr3fairness/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/">
    <span class="fa fa fa fa-comments"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://stackoverflow.com/questions/tagged/mlr3">
    <span class="fab fa fab fa-stack-overflow"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://mlr-org.com/">
    <span class="fa fa-rss"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><div class="section level1">
<div class="page-header"><h1 id="mlr3fairness-">
<a href="https://github.com/mlr-org/mlr3fairness" class="external-link">mlr3fairness</a> <img src="reference/figures/scale_mlr3.png" align="right"><a class="anchor" aria-label="anchor" href="#mlr3fairness-"></a>
</h1></div>
<p>Machine Learning Fairness Extension for <a href="https://github.com/mlr-org/mlr3" class="external-link">mlr3</a>.</p>
<p><a href="https://github.com/mlr-org/mlr3fairness/actions/workflows/r-cmd-check.yml" class="external-link"><img src="https://github.com/mlr-org/mlr3fairness/actions/workflows/r-cmd-check.yml/badge.svg" alt="r-cmd-check"></a> <a href="https://CRAN.R-project.org/package=mlr3fairness" class="external-link"><img src="https://www.r-pkg.org/badges/version/mlr3fairness" alt="CRAN status"></a> <a href="https://stackoverflow.com/questions/tagged/mlr3" class="external-link"><img src="https://img.shields.io/badge/stackoverflow-mlr3-orange.svg" alt="StackOverflow"></a> <a href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/" class="external-link"><img src="https://img.shields.io/badge/chat-mattermost-orange.svg" alt="Mattermost"></a></p>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>Install the development version from github:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">remotes</span><span class="fu">::</span><span class="fu">install_github</span><span class="op">(</span><span class="st">"mlr-org/mlr3fairness"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="why-should-i-care-about-fairness-in-machine-learning">Why should I care about fairness in machine learning?<a class="anchor" aria-label="anchor" href="#why-should-i-care-about-fairness-in-machine-learning"></a>
</h2>
<p>Machine Learning model predictions can be skewed by a range of factors and thus might be considered unfair towards certain groups or individuals. An example would be the COMPAS algorithm, which is a popular commercial algorithm used by judges and parole officers for scoring criminal defendant’s likelihood of reoffending (recidivism). <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" class="external-link">Studies</a> have shown, that the algorithm might be biased in favor of white defendants. Biases can occur in a large variety of situations where algorithms automate or support human decision making e.g. credit checks, automatic HR tools along with a variety of other domains.</p>
<p>The <strong>goal of <code>mlr3fairness</code></strong> is to allow for auditing of <code>mlr3</code> learners, visualization and subsequently trying to improve fairness using debiasing strategies.</p>
<hr>
<p><span class="emoji" data-emoji="warning">⚠️</span> <strong>Note</strong> Bias auditing and debiasing solely based on observational data <strong>can not</strong> guarantee fairness of a decision making system. Several biases, for example comming from the data can not be detected using the approaches implemented in <code>mlr3fairness</code>. The goal of this software is <strong>instead</strong> to allow for a better understanding and first hints at possible fairness problems in a studied model.</p>
<hr>
</div>
<div class="section level2">
<h2 id="feature-overview">Feature Overview<a class="anchor" aria-label="anchor" href="#feature-overview"></a>
</h2>
<ul>
<li><p><a href="#fairness-metrics"><strong>Fairness Measures:</strong></a> Audit algorithmms for fairness using a variety of fairness criteria. This also allows for designing custom criteria.</p></li>
<li><p><a href="#fairness-visualizations"><strong>Fairness Visualizations:</strong></a> Diagnose fairness problems through visualizations.</p></li>
<li><p><a href="#debiasing-methods"><strong>Debiasing Methods:</strong></a> Correct fairness problems in three lines of code.</p></li>
<li><p><a href="#model-cards--datasheets"><strong>Fairness Report:</strong></a> Obtain a report regarding an algorithm’s fairness. (Under development)</p></li>
</ul>
<p><strong>More Information</strong></p>
<ul>
<li><a href="https://mlr3fairness.mlr-org.com/articles/debiasing-vignette.html">Debiasing</a></li>
<li><a href="https://mlr3fairness.mlr-org.com/articles/measures-vignette.html">Fairness Metrics</a></li>
<li><a href="https://mlr3fairness.mlr-org.com/articles/visualization-vignette.html">Visualizations</a></li>
<li><a href="https://mlr3fairness.mlr-org.com/articles/reports-vignette.html">Reports</a></li>
</ul>
<div class="section level3">
<h3 id="protected-attribute">Protected Attribute<a class="anchor" aria-label="anchor" href="#protected-attribute"></a>
</h3>
<p><code>mlr3fairness</code> requires information about the protected attribute wrt. which we want to assess fairness. This can be set via the <code>col_role</code> “pta” (protected attribute).</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">task</span><span class="op">$</span><span class="va">col_roles</span><span class="op">$</span><span class="va">pta</span> <span class="op">=</span> <span class="st">"variable_name"</span></span></code></pre></div>
<p>In case a non-categorical or more complex protected attribute is required, it can be manually computed and added to the task. <code>mlr3fairness</code> does not require specific types for <code>pta</code>, but will compute one metric for every unique value in the <code>pta</code> column.</p>
</div>
<div class="section level3">
<h3 id="fairness-metrics">Fairness Metrics<a class="anchor" aria-label="anchor" href="#fairness-metrics"></a>
</h3>
<p><code>mlr3fairness</code> offers a variety of fairness metrics. Metrics are prefixed with <code>fairness.</code> and can be found in the <code><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">msr()</a></code> dictionary. Most fairness metrics are based on a difference between two protected groups (e.g. male and female) for a given metric (e.g. the false positive rate: <code>fpr</code>). See <a href="https://textbook.coleridgeinitiative.org/chap-bias.html" class="external-link">the vignette</a> for a more in-depth introduction to fairness metrics and how to choose them.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3.mlr-org.com" class="external-link">mlr3</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3fairness.mlr-org.com">mlr3fairness</a></span><span class="op">)</span></span></code></pre></div>
<table class="table">
<colgroup>
<col width="17%">
<col width="82%">
</colgroup>
<thead><tr class="header">
<th align="left">key</th>
<th align="left">description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">fairness.acc</td>
<td align="left">Absolute differences in accuracy across groups</td>
</tr>
<tr class="even">
<td align="left">fairness.mse</td>
<td align="left">Absolute differences in mean squared error across groups</td>
</tr>
<tr class="odd">
<td align="left">fairness.fnr</td>
<td align="left">Absolute differences in false negative rates across groups</td>
</tr>
<tr class="even">
<td align="left">fairness.fpr</td>
<td align="left">Absolute differences in false positive rates across groups</td>
</tr>
<tr class="odd">
<td align="left">fairness.tnr</td>
<td align="left">Absolute differences in true negative rates across groups</td>
</tr>
<tr class="even">
<td align="left">fairness.tpr</td>
<td align="left">Absolute differences in true positive rates across groups</td>
</tr>
<tr class="odd">
<td align="left">fairness.npv</td>
<td align="left">Absolute differences in negative predictive values across groups</td>
</tr>
<tr class="even">
<td align="left">fairness.ppv</td>
<td align="left">Absolute differences in positive predictive values across groups</td>
</tr>
<tr class="odd">
<td align="left">fairness.fomr</td>
<td align="left">Absolute differences in false omission rates across groups</td>
</tr>
<tr class="even">
<td align="left">fairness.fp</td>
<td align="left">Absolute differences in false positives across groups</td>
</tr>
<tr class="odd">
<td align="left">fairness.tp</td>
<td align="left">Absolute differences in true positives across groups</td>
</tr>
<tr class="even">
<td align="left">fairness.tn</td>
<td align="left">Absolute differences in true negatives across groups</td>
</tr>
<tr class="odd">
<td align="left">fairness.fn</td>
<td align="left">Absolute differences in false negatives across groups</td>
</tr>
<tr class="even">
<td align="left">fairness.cv</td>
<td align="left">Difference in positive class prediction, also known as Calders-Wevers gap or demographic parity</td>
</tr>
<tr class="odd">
<td align="left">fairness.eod</td>
<td align="left">Equalized Odds: Mean of absolute differences between true positive and false positive rates across groups</td>
</tr>
<tr class="even">
<td align="left">fairness.pp</td>
<td align="left">Predictive Parity: Mean of absolute differences between ppv and npv across groups</td>
</tr>
<tr class="odd">
<td align="left">fairness.acc_eod=.05</td>
<td align="left">Accuracy under equalized odds &lt; 0.05 constraint</td>
</tr>
<tr class="even">
<td align="left">fairness.acc_ppv=.05</td>
<td align="left">Accuracy under ppv difference &lt; 0.05 constraint</td>
</tr>
</tbody>
</table>
<p>Additional <strong>custom fairness metrics</strong> can be easily constructed, <a href="https://textbook.coleridgeinitiative.org/chap-bias.html" class="external-link">the vignette</a> contains more details. The <code><a href="reference/fairness_tensor.html">fairness_tensor()</a></code> function can be used with a <code>Prediction</code> in order to print group-wise confusion matrices for each protected attribute group. We can furthermore measure fairrness in each group separately using <code>MeasureSubgroup</code> and <code>groupwise_metrics</code>.</p>
</div>
<div class="section level3">
<h3 id="fairness-visualizations">Fairness Visualizations<a class="anchor" aria-label="anchor" href="#fairness-visualizations"></a>
</h3>
<p>Visualizations can be used with either a <code>Prediction</code>, <code>ResampleResult</code> or a <code>BenchmarkResult</code>. For more information regarding those objects, refer to the <a href="https://mlr3book.mlr-org.com/basics.html" class="external-link">mlr3 book</a>.</p>
<ul>
<li><p><strong>fairness_accuracy_tradeoff</strong>: Plot available trade-offs between fairness and model performance.</p></li>
<li><p><strong>compare_metrics</strong>: Compare fairness across models and cross-validation folds.</p></li>
<li><p><strong>fairness_prediction_density</strong>: Density plots for each protected attribute.</p></li>
</ul>
<p><img src="reference/figures/unnamed-chunk-6-1.png"><!-- --></p>
</div>
<div class="section level3">
<h3 id="debiasing-methods">Debiasing Methods<a class="anchor" aria-label="anchor" href="#debiasing-methods"></a>
</h3>
<p>Debiasing methods can be used to improve the fairness of a given model. <code>mlr3fairness</code> includes several methods that can be used together with <code>mlr3pipelines</code> to obtain fair(er) models:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3pipelines.mlr-org.com" class="external-link">mlr3pipelines</a></span><span class="op">)</span></span>
<span><span class="va">lrn</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html" class="external-link">as_learner</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html" class="external-link">po</a></span><span class="op">(</span><span class="st">"reweighing_wts"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html" class="external-link">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">rs</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/resample.html" class="external-link">resample</a></span><span class="op">(</span><span class="va">lrn</span>, task <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">tsk</a></span><span class="op">(</span><span class="st">"compas"</span><span class="op">)</span><span class="op">$</span><span class="fu">filter</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">500</span><span class="op">)</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">rs</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">msr</a></span><span class="op">(</span><span class="st">"fairness.acc"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><strong>Overview:</strong></p>
<table style="width:100%;" class="table">
<colgroup>
<col width="18%">
<col width="14%">
<col width="21%">
<col width="23%">
<col width="22%">
</colgroup>
<thead><tr class="header">
<th align="left">key</th>
<th align="right">output.num</th>
<th align="left">input.type.train</th>
<th align="left">input.type.predict</th>
<th align="left">output.type.train</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">EOd</td>
<td align="right">1</td>
<td align="left">TaskClassif</td>
<td align="left">TaskClassif</td>
<td align="left">NULL</td>
</tr>
<tr class="even">
<td align="left">reweighing_os</td>
<td align="right">1</td>
<td align="left">TaskClassif</td>
<td align="left">TaskClassif</td>
<td align="left">TaskClassif</td>
</tr>
<tr class="odd">
<td align="left">reweighing_wts</td>
<td align="right">1</td>
<td align="left">TaskClassif</td>
<td align="left">TaskClassif</td>
<td align="left">TaskClassif</td>
</tr>
</tbody>
</table>
</div>
<div class="section level3">
<h3 id="fair-learners">Fair Learners<a class="anchor" aria-label="anchor" href="#fair-learners"></a>
</h3>
<p><code>mlr3fairness</code> furthermore contains several learners that can be used to directly learn fair models:</p>
<table class="table">
<thead><tr class="header">
<th align="left">key</th>
<th align="left">package</th>
<th align="left">reference</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">regr.fairfrrm</td>
<td align="left">fairml</td>
<td align="left">Scutari et al., 2021</td>
</tr>
<tr class="even">
<td align="left">classif.fairfgrrm</td>
<td align="left">fairml</td>
<td align="left">Scutari et al., 2021</td>
</tr>
<tr class="odd">
<td align="left">regr.fairzlm</td>
<td align="left">fairml</td>
<td align="left">Zafar et al., 2019</td>
</tr>
<tr class="even">
<td align="left">classif.fairzlrm</td>
<td align="left">fairml</td>
<td align="left">Zafar et al., 2019</td>
</tr>
<tr class="odd">
<td align="left">regr.fairnclm</td>
<td align="left">fairml</td>
<td align="left">Komiyama et al., 2018</td>
</tr>
</tbody>
</table>
</div>
<div class="section level3">
<h3 id="datasets">Datasets<a class="anchor" aria-label="anchor" href="#datasets"></a>
</h3>
<p><code>mlr3fairness</code> includes two fairness datasets: <code>adult</code> and <code>compas</code>. See <code><a href="reference/adult.html">?adult</a></code> and <code><a href="reference/compas.html">?compas</a></code> for additional information regarding columns.</p>
<p>You can load them using <code>tsk(&lt;key&gt;)</code>.</p>
</div>
<div class="section level3">
<h3 id="model-cards--datasheets">Model Cards &amp; Datasheets<a class="anchor" aria-label="anchor" href="#model-cards--datasheets"></a>
</h3>
<p>An important step towards achieving more equitable outcomes for ML models is adequate documentation for datasets and models in machine learning. <code>mlr3fairness</code> comes with reporting aides for <code>models</code> and <code>datasets</code>. This provides empty templates that can be used to create interactive reports through <code>RMarkdown</code>.</p>
<table class="table">
<colgroup>
<col width="13%">
<col width="17%">
<col width="15%">
<col width="52%">
</colgroup>
<thead><tr class="header">
<th>Report</th>
<th>Description</th>
<th>Reference</th>
<th>Example</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>report_modelcard</code></td>
<td>Modelcard for ML models</td>
<td>Mitchell et al., 2018</td>
<td><a href="https://mlr3fairness.mlr-org.com/articles/modelcard/modelcard.html">link</a></td>
</tr>
<tr class="even">
<td><code>report_datasheet</code></td>
<td>Datasheet for data sets</td>
<td>Gebru et al., 2018</td>
<td><a href="https://mlr3fairness.mlr-org.com/articles/datasheet/datasheet.html">link</a></td>
</tr>
<tr class="odd">
<td><code>report_fairness</code></td>
<td>Fairness Report</td>
<td>-<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;The fairness report is inspired by the &lt;a href="http://aequitas.dssg.io/example.html" class="external-link"&gt;Aequitas Bias report&lt;/a&gt;.&lt;/p&gt;'><sup>1</sup></a>
</td>
<td><a href="https://mlr3fairness.mlr-org.com/articles/fairness/fairness.html">link</a></td>
</tr>
</tbody>
</table>
<p><strong>Usage:</strong></p>
<p>The <code>report_*</code> functions instantiate a new <code>.Rmd</code> template that contains a set of pre-defined questions which can be used for reporting as well as initial graphics. The goal is that a user extends this <code>.Rmd</code> file to create comprehensive documentation for datasets, ML models or to document a model’s fairness. It can later be converted into a <code>html</code> report using<code>rmarkdown</code>’s <code>render</code>.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rmdfile</span> <span class="op">=</span> <span class="fu"><a href="reference/report_datasheet.html">report_datasheet</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu">rmarkdown</span><span class="fu">::</span><span class="fu"><a href="https://pkgs.rstudio.com/rmarkdown/reference/render.html" class="external-link">render</a></span><span class="op">(</span><span class="va">rmdfile</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="demo-for-adult-dataset">Demo for Adult Dataset<a class="anchor" aria-label="anchor" href="#demo-for-adult-dataset"></a>
</h3>
<p>We provide a short example detailing how <code>mlr3fairness</code> integrates with the <code>mlr3</code> ecosystem.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3fairness.mlr-org.com">mlr3fairness</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co">#Initialize Fairness Measure</span></span>
<span><span class="va">fairness_measure</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">msr</a></span><span class="op">(</span><span class="st">"fairness.fpr"</span><span class="op">)</span></span>
<span><span class="co">#Initialize tasks</span></span>
<span><span class="va">task_train</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">tsk</a></span><span class="op">(</span><span class="st">"adult_train"</span><span class="op">)</span></span>
<span><span class="va">task_test</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">tsk</a></span><span class="op">(</span><span class="st">"adult_test"</span><span class="op">)</span></span>
<span><span class="co">#Initialize model</span></span>
<span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#Verify fairness metrics</span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">task_train</span><span class="op">)</span></span>
<span><span class="va">predictions</span> <span class="op">=</span> <span class="va">learner</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">task_test</span><span class="op">)</span></span>
<span><span class="va">predictions</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">fairness_measure</span>, task <span class="op">=</span> <span class="va">task_test</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#Visualize the predicted probability score based on protected attribute.</span></span>
<span><span class="fu"><a href="reference/fairness_prediction_density.html">fairness_prediction_density</a></span><span class="op">(</span><span class="va">predictions</span>, <span class="va">task_test</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="extensions">Extensions<a class="anchor" aria-label="anchor" href="#extensions"></a>
</h3>
<ul>
<li>The <a href="https://github.com/mlr-org/mcboost" class="external-link">mcboost</a> package integrates with <strong>mlr3</strong> and offers additional debiasing post-processing functionality for <strong>classification</strong>, <strong>regression</strong> and <strong>survival</strong>.</li>
</ul>
</div>
<div class="section level3">
<h3 id="other-fairness-toolkits-in-r">Other Fairness Toolkits in R<a class="anchor" aria-label="anchor" href="#other-fairness-toolkits-in-r"></a>
</h3>
<ul>
<li>The <a href="https://aif360.mybluemix.net/" class="external-link">AI Fairness 360</a> toolkit offers an R extension that allows for bias auditing, visualization and mitigation.</li>
<li>
<a href="https://github.com/ModelOriented/fairmodels/" class="external-link">fairmodels</a> integrates with the <a href="https://github.com/ModelOriented/DALEX" class="external-link">DALEX</a> R-packages and similarly allows for bias auditing, visualization and mitigation.</li>
<li>The <a href="https://github.com/kozodoi/fairness" class="external-link">fairness</a> package allows for bias auditing in R.</li>
<li>The <a href="https://cran.r-project.org/package=fairml" class="external-link">fairml</a> package contains methods for learning de-biased regression and classification models. Learners from <code>fairml</code> are included as learners in <code>mlr3fairness</code>.</li>
</ul>
</div>
<div class="section level3">
<h3 id="other-fairness-toolkits">Other Fairness Toolkits<a class="anchor" aria-label="anchor" href="#other-fairness-toolkits"></a>
</h3>
<ul>
<li>
<a href="http://aequitas.dssg.io/" class="external-link">Aequitas</a> Allows for constructing a fairness report for different fairness metrics along with visualization in Python.</li>
<li>
<a href="https://fairlearn.org/" class="external-link">fairlearn</a> Allows for model auditing and debiasing as well as visualization in Python.</li>
<li>
<a href="https://github.com/Trusted-AI/AIF360" class="external-link">AI Fairness 360</a> Allows for model auditing and debiasing as well as visualization in R and Python.</li>
</ul>
</div>
<div class="section level3">
<h3 id="future-development">Future Development<a class="anchor" aria-label="anchor" href="#future-development"></a>
</h3>
<p>Several future developments are currently planned. Contributions are highly welcome!</p>
<ul>
<li>Visualizations: Improvement on visualizations, like anchor points and others. See issues.</li>
<li>Debiasing Methods: More debiasing methods, post-processing and in-processing.</li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="bugs-feedback-and-questions">Bugs, Feedback and Questions<a class="anchor" aria-label="anchor" href="#bugs-feedback-and-questions"></a>
</h2>
<p><code>mlr3fairness</code> is a free and open source software project that encourages participation and feedback. If you have any issues, questions, suggestions or feedback, please do not hesitate to open an “issue” about it on the GitHub page! In case of problems / bugs, it is often helpful if you provide a “minimum working example” that showcases the behaviour.</p>
</div>
</div>


  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://cloud.r-project.org/package=mlr3fairness" class="external-link">View on CRAN</a></li>
<li><a href="https://github.com/mlr-org/mlr3fairness/" class="external-link">Browse source code</a></li>
<li><a href="https://github.com/mlr-org/mlr3fairness/issues" class="external-link">Report a bug</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="https://www.r-project.org/Licenses/LGPL-3" class="external-link">LGPL-3</a></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing mlr3fairness</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Florian Pfisterer <br><small class="roles"> Maintainer, author </small> <a href="https://orcid.org/0000-0001-8867-762X" target="orcid.widget" aria-label="ORCID" class="external-link"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a> </li>
<li>Wei Siyi <br><small class="roles"> Author </small>  </li>
<li>Michel Lang <br><small class="roles"> Author </small> <a href="https://orcid.org/0000-0001-9754-0393" target="orcid.widget" aria-label="ORCID" class="external-link"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a> </li>
</ul>
</div>



  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Florian Pfisterer, Wei Siyi, Michel Lang.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
